# 数据挖掘入门

## 数据挖掘概念:

所谓数据挖掘，是指在数据中挖掘有价值的信息，最早定义的数据挖掘是KDD的一个步骤，后随着挖掘的应用场景不断丰富，其技术有了长足的发展，如今的数据挖掘，其概念无论从内涵还是外延角度而言都已独立成为一门学科。

数据:

当今数据挖掘中的数据，一般指经采集后存放在数据库中数据。

挖掘: 

对数据库中有价值信息进行挖掘的过程，当前主要挖掘手段是利用算法模型对数据进行分析。

 

## 数据分析师的核心技能

数据挖掘是数据分析工作的核心，也是数据分析师的核心技能

**业务知识**: 分析工作所涉及的实际业务背景相关知识

**分析方法**: 分析过程所涉及到的方法论

**实践工具**: 算法实践落地所需要的计算工具.

分析方法落地实践工具，可分类单机计算工具和分布式计算工具两种

 

分析方法: 

**分析方法依其涉及方法复杂程度进行划分:** 

 

**简单查询**：对数据进行简单查询，依据查询结果制定决策，常用SQL结构化查询语言来执行该方面工作。

 

**报表系统**：数据查询系统的更高级形式，利用分组、求和、排序等方法对数据进行整理，然后输出结果，常用表工具Excel、BI工具Tableau或分布式数据仓库工具Hive等。

 

**数理统计分析**：利用数理统计算法执行分析任务，常用数理统计算法包括假设检验、方差分析、线性回归等算法。

 

**机器学习**：利用机器学习算法执行分析任务，和数理统计算法不同，机器学习类算法强调数据训练、过程的迭代和结果的收敛。

## 算法分类: 

### 从算法理论层面:

1.    数理统计

基于统计学原理涉及的一系列算法,大多是基于少量样本的统计推断, 其算法虽然大多诞生较早, 但在当今数据环境中仍然能发挥巨大价值. 

2.    机器学习

机器学习类算法需要更多的计算资源即数据量支撑, 计算前无需预设过多条件, 运算过程中会不断迭代, 直至收敛.

### 从算法应用情景: 

**有监督学习**: 再有标签数据上执行的分类, 回归或者预测类算法.(比如说分类问题, 这行样本是哪一类的,是包含标签的.例如回归, 每一行一定要有一个Y值, )(基于历史经验对接下来可能发生的行为做一个预判)

**无监督学习**: 在无标签的数据上执行聚类, 频繁项挖掘等算法.(我们去探究本身这个数据集可能具有哪些数据, 例如聚类, 怎么聚类比较好, 不存在固定标准.我们采用不同方法去聚类, 可以视作对数据本身的情况做一种探索.例如频繁项挖掘, 购物篮中哪些商品可有可能出现在一块. 根据这么一个数据集对超市中的物品摆放顺序做一个调整.)

**半监督学习**,  **强化学习**(打破有无标签的界限, 半监督学习可以自己生成一些标签. 强化学习对标签进行反复利用.)…..

 

|             | 数理统计                                                 | 机器学习                                           |
| ----------- | -------------------------------------------------------- | -------------------------------------------------- |
| 有监督学习: | 线性回归,   逻辑回归,   时间序列,   岭回归,   贝叶斯网络 | KNN  决策树  神经网络  支持向量机                  |
| 无监督学习  | 假设检验  参数估计                                       | 聚类分析  协同过滤(猜你喜欢)  关联规则(挖掘频繁项) |

 

整个算法的框架需要有所了解

算法学习阶段划分: 

1.    基于MLlib的算法学习阶段 : 主要以掌握算法执行一般流程, 常用算法简单使用方法为主, 包括了解算法作用对象, 算法执行过程输入参数接口, 输出结果解读等. 同时掌握MLlib工具的使用方法

2.    Python机器学习: 进一步深入了解算法原理, 了解同一类型不同算法之间差别, 能够根据不同应用情景选择算法, 根据算法原理优化算法. 同时掌握sk-learn算法库的使用方法.

3.    后续深造: 根据实际工作中需求进一步深化对算法的理解, 进一步强化数学基础, 能够自主编写复杂算法代码应对不同分析目标.

### 学习一个的算法的过程

1.    了解它的基本原理

2.    了解它的数学原理

3.    写成伪代码

4.    转换成代码

 

Python是一个胶水语言, 在各种地方都可以用python来执行一些内容.

Python如果先学可能已经忘了, 打下来一个知识框架, 

大数据集群学习, 只是我们的一个框架,并不是我们的核心.

核心是算法.

 

数据挖掘导论

机器学习实战

考研三件套

 

### 基于海量数据的机器学习

**传统的机器学习**：由于技术方面的限制，只能在单机上运行，计算资源和存储资源有限，因此传统机器学习大多依赖于数据抽样，但实际上，在随机采样过程中误差无法避免，外加受到计算资源限制无法进行高维运算和深度迭代，因此算法发展有所局限。

**基于MapReduce的机器学习：**随着 HDFS(Hadoop Distributed File System) 等分布式文件系统出现，存储海量数据已经成为可能。在全量数据上进行机器学习也成为了可能，这顺便也解决了统计随机性的问题。然而，由于 MapReduce 自身设计框架的限制，每次计算中间结果都必须存于磁盘，而机器学习本身用到的最多的计算就是迭代计算，这导致MapReduce在实现分布式计算会非常耗时以及会消耗大量的磁盘I/O，这对迭代频发的运算时致命的性能瓶颈。

**基于Spark的机器学习：**在大数据上进行机器学习，需要处理全量数据并进行大量的迭代计算，这要求机器学习平台具备强大的处理能力。Spark 立足于内存计算，天然的适应于迭代式计算。同时，Spark提供了Shell即系查询，以及一系列针对不同数据抽象的计算框架，逐渐使得Spark成为目前机器学习最常用的计算框架。

 

MLlib是Spark的机器学习（Machine Learning）库，旨在简化机器学习的工程实践工作，并方便扩展到更大规模。MLlib由一些通用的学习算法和工具组成，包括分类、回归、聚类、协同过滤、降维等，同时还包括底层的优化原语和高层的管道API。具体来说，其主要包括以下几方面的内容：

 

 

### Spark MLlib机器学习算法库

算法工具：常用的学习算法，如分类、回归、聚类和协同过滤；

特征化工具：特征提取、转化、降维，和选择工具；

管道(Pipeline)：用于构建、评估和调整机器学习管道的工具;

持久性：保存和加载算法，模型和管道;

实用工具：线性代数，统计，数据处理等工具。

### 数据分析一般流程

1.    数据探索

a)     根据分析目标提取数据，结合业务经验选取相关字段，并对数据情况进行简单了解

2.    数据预处理

a)     根据分析目标及可能选取的方法对数据进行清洗，包括列属性转换、数据降维、假设检验、相关性检验、缺失值填补等工作

3.    数据分析

a)     选择算法执行，或训练模型组建机器学习算法流执行分析任务，产出算法执行结论

4.    反馈调优

a)     根据输出结果制定模型优化方案，通过调整参数、更换算法或重新设计算法进行调优

 

### 机器学习一般流程

The definition of Machine learning：

A computer program is said to learn fromexperience E with respect to some class of tasks T and performance measure P,if its performance at tasks in T, as measured by P, improves with experience E

![1525084666598](/pictures/6)

### MLlib基本结构

![1525084732623](/pictures/7)

![1525084747704](/pictures/8)

 



### 数据分析中经常用的数据类型

离散型变量: 整数型—有序变量, 名义变量(有序变量, 大小之间的关系是有一定含义的, 例如将学历按照等级换成数字)(名义变量, 例如学号)

连续型变量: 等距, 等比(一般不用)

 

机器的逻辑是按照自己的逻辑去执行的, 而不是按照你的逻辑去执行的.

 

在矩阵的转置事件中, 我表现出的感觉是不屑, 而老师的态度是支持.

这是我的不足, 与局限.

所有得到的数据都是样本

一次抽样中, 小概率事件不可能发生, 如果发生了, 说明你的假设是错的.



## MLlib学习记录

