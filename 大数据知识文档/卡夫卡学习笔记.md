# **4月19日**

## 卡夫卡的架构特点

卡夫卡也是基于scala编译的, 因此需要考虑到scala是哪个版本.

1. 可拓展
2. Flume进程需要手动启动, 需要人工参与设置, Kafka不需要
3. 解耦性: 降低自身复杂度, 能被很好的嵌入其他的应用中去, 可以嵌入到Flume的sink, 也可以充当source.
4. 峰值处理, 高峰期的时候, 相当于一个非常大的缓冲区, 在数据量暴增的时候, 能够保持平稳的输出.

### kafka基本结构

#### Producer: 

消费生产者, 针对集群内部

#### Broker：

一个Kafka的实例就是一个Broker，相当于Flume中的Agent；

#### Topic：

主题，Kafka中同一类型数据集的名称，相当于数据库中的表，Producer将同一类型数据写入同一个Topic中，同一个Consumer或Consumer Group从同一个Topic中消费数据，同时，一个Topic在物理上会被分成多分存储到不同的物理机上；

#### Partition：

分区，一个Topic可设置多个分区，相当于把一个数据集分成多分，存储到不同分区中进行存储（类似于HDFS），分区命名规则为topicname-index；

#### Segment: 

段文件, Kafka中最小存储单位, 一个topic包含多个Partition, 一个Partition又包含了多个Segment, Segment以其内部消息的起始偏移量进行索引.

#### Offset: 

消息的起始偏移量, 可作为Segment的索引.

#### Replication: 

副本, 一个Partition可以有一个或多个副本, 为了保证整个Kafka集群容错性.

#### Consumer Group: 

消费者组,  一个Consumer Group可包含一个或多个Consumer, 当一个topic被一个消费者组消费的时候, 一条消息只能由其中一位消费者消费, 不会出现多位消费者消费同一条消息的过程

#### Zookeeper: 

kafka需要ZooKeeper对其进行协调管理，安装Kafka过程将自带一个ZooKeeper。

## 我们在使用Kafka过程中使用的命令:

1)bin/zookeeper-server-start.sh config/zookeeper.properties/master1号上启动zookeeper服务
2)bin/kafka-server-start.sh config/server.properties/master2号启动kafka服务
3）bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic cda//master3号上开个topic
4）bin/kafka-topics.sh --list --zookeeper localhost:2181  /看一下list
5）bin/kafka-console-producer.sh --broker-list localhost:9092 --topic cda/producer开始传数据
6）bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic cda --from-beginning//consumer消费接收 

 ~/kafka/bin/kafka-server-start.sh ~/kafka/config/server.properties
~/kafka/bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 2 --partitions 3 --topic CDA
~/kafka/bin/kafka-topics.sh --describe --zookeeper master:2181,slave1:2181,slave2:2181
~/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic CDA

#  

 