## 第一个阶段:描述性统计

刚开始都是描述性统计, 在数理统计出现之前. 求个平均值, 求个中位数, 求个众数等等, 就是描述性分析.求个标准差.

有一些指数, 同比, 环比发展速度.

后来发展起来的还有商业BI

其实就是商业BI, 大数据BI, 大家都不懂的情况下就看图, 那个图很炫酷, 就很好了.

## 第二个阶段:数理统计

数理统计分析, 抽样估计, 方差分析, 假设检验

微积分 + 概率论产生数理统计.

用这个正态分布曲线描述, 我们这个世界上很多.

统计学就是也是在算命, 也是在推断, 但是有微积分和数理统计在后面做支撑.

大家在干的事情, 都是在做推断, 推断我明年能赚多少钱.

## 第三个阶段: 数据挖掘

从人的客观思维来的, 最早就是关联规则, 结合了人工智能, 机器学习, 数据库.等发展起来的

### 数据挖掘的种类:

聚类分析

分类分析:

因为我们人类最喜欢做的就是分类

1. 决策树, 神经网络, 支持向量机, 随机森林

关联规则

协同过滤

## 第四个阶段:	大数据分析

面对海量数据, 数据量大到一定程度, 利用大数据技术, 利用数据挖掘, 解决实际的商业问题.

北京每天进出一百五十万辆车, 进出经过两次, 300万次, 在数据库里面就是300万行.

并且这只是结构化数据.

非结构化数据就更多了.

四个感应器, 第一个圈, 感应到有一个圈.第二个感应器, 抓到车牌号码, 第三个, 摄像头, 拍摄下来一张图片.

第四个感应器: 摄像头.从头到尾录下来数据.

北京市有八百个摄像头.

## 进入行业以后的工作方法

大家将来进入一个行业, 大家要知道, 做你这个行业有什么样的数据来源.

对数据敏感, 第二个, 找行业需求, 有一个什么样的想法.

我根据我的这个数据, 把这个想法给实现了.



比如说, 农业大数据, 就很扯, 为什么, 因为根本没有数据来源.

交通大数据, 有数据, 但是数据质量不行, 我们天天就做数据质量评估.

中国现在的现状是小数据还没搞好, 就搞大数据.



能解决商业问题就行了, 你无论是用小数据还是大数据, 

**最关键的是你对这个行业的理解, 能不能抓住行业的痛点.**

面试的时候就要问数据的情况, 你的数据是从来的.

**必须要产生商业价值**, 这是我们一切的核心, 否则就没有意义, 你那是玩.



## 深度学习

现在一个GPU的价格是15万, 当我做工程的时候, 这个成本是很高的.

如果能放到Hadoop上面来, 可能就5, 6万, 这是一个很大的突破.



## 数据分析目标--路网收费管理问题

十几个收费站, 每个都能算出来一个收费金额.

有一天突然, 收入增加了50%.

我想要找出为什么会发生这样的情况.

我要找出哪个出入口, 使得收入额变化情况.

这就是商业BI的事情.

如果我要分析一个收费口, 就是小数据.

如果我要分析整个全部收费站的情况, 分析历史情况.

**不能在业务系统上面去干这个事情.**

可能要先把业务系统的数据抽取出来.

1. 模拟数据的生成
2. 使用sqoop抽取数据进入hive中, 如果不想对业务系统产生影响, 要用到备份机.
3. 使用spark-sql进行数据归约和预处理, 写入hive, 能用描述性分析解决一定要先用描述性分析, 不用搞复杂了.
4. 使用sqoop从hive中提取到mysql中
5. 对mysql中的数据使用tableau进行分析和展示

如果你做完是一份报告, 那就数据组的人做完就完了.

但是一般情况下, 要在工程中应用, 要在前端展示.

## 整个内容讲完以后

主要涉及到怎么把这整个东西串联起来.

## 作业

saprk中直接将数据写入到mysql 中, 涉及spark程序.

可以根据现有数据进行更深入的分析, 解决业务问题.

1. 做多元线性回归的思路
   - 每一行为某一天的数据
   - Y为每天收费的环比增长率
   - X为每个入口环比增长率
   - 计算三个月的数据, 算出每个入口的贡献率(最大的入口我要保证每天都开放, 用最好的人员设备)(如何算呢? )
2. 计算外地车辆的贡献率
3. 职住分析



曹老师QQ号: 17842878